# -*- coding: utf-8 -*-
"""
AI ì´ë¯¸ì§€ ë¶„ë¥˜ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜
ì‚¬ìš©ìê°€ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì—¬ AI ìƒì„± ì´ë¯¸ì§€ì¸ì§€ ì‹¤ì œ ì´ë¯¸ì§€ì¸ì§€ íŒë³„í•˜ëŠ” ì›¹ì‚¬ì´íŠ¸
"""

from flask import Flask, render_template, request, jsonify, redirect, url_for
import os
import uuid
from datetime import datetime
import json
from werkzeug.utils import secure_filename
import torch
from transformers import pipeline, ViTForImageClassification, ViTImageProcessor
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
import io
import base64
import threading
import time
from pathlib import Path
from datetime import timedelta
from model_retrain import ModelRetrainer

# Flask ì•± ì´ˆê¸°í™”
app = Flask(__name__)
app.config['SECRET_KEY'] = 'ai-image-detector-2024'
app.config['UPLOAD_FOLDER'] = 'static/uploads'
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB ìµœëŒ€ íŒŒì¼ í¬ê¸°

# í—ˆìš©ëœ íŒŒì¼ í™•ì¥ì
ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif', 'bmp', 'tiff'}

# ì—…ë¡œë“œ í´ë” ìƒì„±
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)
os.makedirs('static/results', exist_ok=True)
os.makedirs('data/feedback', exist_ok=True)
os.makedirs('logs', exist_ok=True)

# ì „ì—­ ë³€ìˆ˜
retrainer = None
retraining_status = {'status': 'idle', 'progress': 0, 'message': ''}

# AI ëª¨ë¸ ë¡œë“œ
print("ğŸ¤– AI ëª¨ë¸ ë¡œë”© ì¤‘...")
try:
    # ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì •
    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:64'
    os.environ['TOKENIZERS_PARALLELISM'] = 'false'
    
    # í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ
    model_path = './ai_vs_real_image_detection'
    device = 0 if torch.cuda.is_available() else -1
    
    # íŒŒì´í”„ë¼ì¸ ìƒì„± (ë©”ëª¨ë¦¬ ìµœì í™”)
    classifier = pipeline(
        'image-classification',
        model=model_path,
        device=device,
        torch_dtype=torch.float16 if device == 0 else torch.float32
    )
    
    # ê°œë³„ ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œë„ ë¡œë“œ (ìƒì„¸ ë¶„ì„ìš©)
    model = ViTForImageClassification.from_pretrained(
        model_path,
        torch_dtype=torch.float16 if device == 0 else torch.float32
    )
    processor = ViTImageProcessor.from_pretrained(model_path)
    
    print(f"âœ… AI ëª¨ë¸ ë¡œë“œ ì™„ë£Œ! (ë””ë°”ì´ìŠ¤: {'GPU' if device == 0 else 'CPU'})")
    
except Exception as e:
    print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    classifier = None
    model = None
    processor = None

def allowed_file(filename):
    """í—ˆìš©ëœ íŒŒì¼ í™•ì¥ìì¸ì§€ í™•ì¸"""
    return '.' in filename and \
           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def save_feedback(image_path, prediction, confidence, user_feedback, correct_label):
    """ì‚¬ìš©ì í”¼ë“œë°±ì„ ì €ì¥"""
    feedback_data = {
        'timestamp': datetime.now().isoformat(),
        'image_path': image_path,
        'prediction': prediction,
        'confidence': confidence,
        'user_feedback': user_feedback,
        'correct_label': correct_label
    }
    
    feedback_file = f"data/feedback/feedback_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}.json"
    
    with open(feedback_file, 'w', encoding='utf-8') as f:
        json.dump(feedback_data, f, ensure_ascii=False, indent=2)
    
    return feedback_file

def analyze_image_features(image_path):
    """ì´ë¯¸ì§€ì˜ íŠ¹ì§•ì„ ë¶„ì„í•˜ì—¬ ì„¤ëª… ìƒì„±"""
    try:
        image = Image.open(image_path).convert('RGB')
        
        # ì´ë¯¸ì§€ ê¸°ë³¸ ì •ë³´
        width, height = image.size
        aspect_ratio = width / height
        
        # ì´ë¯¸ì§€ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
        img_array = np.array(image)
        
        # ê¸°ë³¸ í†µê³„
        mean_brightness = np.mean(img_array)
        std_brightness = np.std(img_array)
        
        # ìƒ‰ìƒ ë¶„ì„
        r_mean, g_mean, b_mean = np.mean(img_array, axis=(0, 1))
        
        # íŠ¹ì§• ê¸°ë°˜ ì„¤ëª… ìƒì„±
        features = {
            'size': f"{width}x{height}",
            'aspect_ratio': round(aspect_ratio, 2),
            'brightness': round(mean_brightness, 1),
            'contrast': round(std_brightness, 1),
            'dominant_colors': {
                'red': round(r_mean, 1),
                'green': round(g_mean, 1),
                'blue': round(b_mean, 1)
            }
        }
        
        return features
        
    except Exception as e:
        print(f"ì´ë¯¸ì§€ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return None

def generate_explanation(prediction, confidence, features):
    """ì˜ˆì¸¡ ê²°ê³¼ì— ëŒ€í•œ ì„¤ëª… ìƒì„±"""
    if prediction == 'REAL':
        explanation = f"ì´ ì´ë¯¸ì§€ëŠ” ì‹¤ì œ ì‚¬ì§„ìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤ (ì‹ ë¢°ë„: {confidence:.1%}). "
        
        if features:
            if features['contrast'] > 50:
                explanation += "ë†’ì€ ëŒ€ë¹„ì™€ ìì—°ìŠ¤ëŸ¬ìš´ ìƒ‰ìƒ ë¶„í¬ê°€ ì‹¤ì œ ì‚¬ì§„ì˜ íŠ¹ì§•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. "
            if features['brightness'] > 100:
                explanation += "ì ì ˆí•œ ë°ê¸°ì™€ ìì—°ìŠ¤ëŸ¬ìš´ ì¡°ëª…ì´ ì‹¤ì œ í™˜ê²½ì—ì„œ ì´¬ì˜ëœ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. "
            
            explanation += f"ì´ë¯¸ì§€ í¬ê¸°ëŠ” {features['size']}ì´ë©°, ì¢…íš¡ë¹„ëŠ” {features['aspect_ratio']}ì…ë‹ˆë‹¤."
    else:
        explanation = f"ì´ ì´ë¯¸ì§€ëŠ” AIê°€ ìƒì„±í•œ ê²ƒìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤ (ì‹ ë¢°ë„: {confidence:.1%}). "
        
        if features:
            if features['contrast'] < 30:
                explanation += "ë‚®ì€ ëŒ€ë¹„ì™€ ë¶€ìì—°ìŠ¤ëŸ¬ìš´ ìƒ‰ìƒ ë¶„í¬ê°€ AI ìƒì„± ì´ë¯¸ì§€ì˜ íŠ¹ì§•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. "
            if features['brightness'] < 80 or features['brightness'] > 200:
                explanation += "ë¶€ìì—°ìŠ¤ëŸ¬ìš´ ë°ê¸°ë‚˜ ì¡°ëª…ì´ AI ìƒì„± ì´ë¯¸ì§€ì˜ íŠ¹ì§•ì…ë‹ˆë‹¤. "
            
            explanation += f"ì´ë¯¸ì§€ í¬ê¸°ëŠ” {features['size']}ì´ë©°, ì¢…íš¡ë¹„ëŠ” {features['aspect_ratio']}ì…ë‹ˆë‹¤."
    
    return explanation

@app.route('/')
def index():
    """ë©”ì¸ í˜ì´ì§€"""
    return render_template('index.html')

@app.route('/upload', methods=['POST'])
def upload_file():
    """ì´ë¯¸ì§€ ì—…ë¡œë“œ ë° ë¶„ì„"""
    if 'file' not in request.files:
        return jsonify({'error': 'íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}), 400
    
    file = request.files['file']
    
    if file.filename == '':
        return jsonify({'error': 'íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}), 400
    
    if not allowed_file(file.filename):
        return jsonify({'error': 'ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. (PNG, JPG, JPEG, GIF, BMP, TIFFë§Œ ì§€ì›)'}), 400
    
    if classifier is None:
        return jsonify({'error': 'AI ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}), 500
    
    try:
        # íŒŒì¼ ì €ì¥
        filename = secure_filename(file.filename)
        unique_filename = f"{uuid.uuid4().hex}_{filename}"
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], unique_filename)
        file.save(filepath)
        
        # ì´ë¯¸ì§€ ë¶„ì„
        result = classifier(filepath)
        
        # ê²°ê³¼ ì²˜ë¦¬
        prediction = result[0]['label']
        confidence = result[0]['score']
        
        # ì´ë¯¸ì§€ íŠ¹ì§• ë¶„ì„
        features = analyze_image_features(filepath)
        
        # ì„¤ëª… ìƒì„±
        explanation = generate_explanation(prediction, confidence, features)
        
        # ê²°ê³¼ ì €ì¥
        result_data = {
            'filename': unique_filename,
            'original_filename': filename,
            'prediction': prediction,
            'confidence': confidence,
            'explanation': explanation,
            'features': features,
            'timestamp': datetime.now().isoformat()
        }
        
        return jsonify({
            'success': True,
            'result': result_data
        })
        
    except Exception as e:
        return jsonify({'error': f'ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}), 500

@app.route('/feedback', methods=['POST'])
def submit_feedback():
    """ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘"""
    try:
        data = request.json
        image_path = data.get('image_path')
        prediction = data.get('prediction')
        confidence = data.get('confidence')
        user_feedback = data.get('user_feedback')  # 'correct' ë˜ëŠ” 'incorrect'
        correct_label = data.get('correct_label')  # 'REAL' ë˜ëŠ” 'FAKE'
        
        if not all([image_path, prediction, confidence, user_feedback, correct_label]):
            return jsonify({'error': 'í•„ìˆ˜ ì •ë³´ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.'}), 400
        
        # í”¼ë“œë°± ì €ì¥
        feedback_file = save_feedback(image_path, prediction, confidence, user_feedback, correct_label)
        
        return jsonify({
            'success': True,
            'message': 'í”¼ë“œë°±ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!',
            'feedback_file': feedback_file
        })
        
    except Exception as e:
        return jsonify({'error': f'í”¼ë“œë°± ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}), 500

@app.route('/about')
def about():
    """ì†Œê°œ í˜ì´ì§€"""
    return render_template('about.html')

@app.route('/stats')
def stats():
    """í†µê³„ í˜ì´ì§€"""
    # í”¼ë“œë°± ë°ì´í„° ìˆ˜ì§‘
    feedback_files = []
    feedback_dir = 'data/feedback'
    
    if os.path.exists(feedback_dir):
        for file in os.listdir(feedback_dir):
            if file.endswith('.json'):
                feedback_files.append(os.path.join(feedback_dir, file))
    
    # í†µê³„ ê³„ì‚°
    total_feedback = len(feedback_files)
    correct_predictions = 0
    incorrect_predictions = 0
    
    for file_path in feedback_files:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if data.get('user_feedback') == 'correct':
                    correct_predictions += 1
                else:
                    incorrect_predictions += 1
        except:
            continue
    
    accuracy = (correct_predictions / total_feedback * 100) if total_feedback > 0 else 0
    
    stats_data = {
        'total_feedback': total_feedback,
        'correct_predictions': correct_predictions,
        'incorrect_predictions': incorrect_predictions,
        'accuracy': round(accuracy, 1)
    }
    
    return render_template('stats.html', stats=stats_data)

@app.route('/retrain', methods=['POST'])
def start_retraining():
    """ëª¨ë¸ ì¬í•™ìŠµ ì‹œì‘"""
    global retrainer, retraining_status
    
    try:
        if retraining_status['status'] == 'running':
            return jsonify({'error': 'ì¬í•™ìŠµì´ ì´ë¯¸ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.'}), 400
        
        # í”¼ë“œë°± ë°ì´í„° í™•ì¸
        feedback_files = list(Path('data/feedback').glob('*.json'))
        if len(feedback_files) < 50:
            return jsonify({
                'error': f'í”¼ë“œë°± ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. (í˜„ì¬: {len(feedback_files)}/50)',
                'required': 50,
                'current': len(feedback_files)
            }), 400
        
        # ì¬í•™ìŠµ ìƒíƒœ ì´ˆê¸°í™”
        retraining_status = {
            'status': 'running',
            'progress': 0,
            'message': 'ì¬í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...'
        }
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì¬í•™ìŠµ ì‹¤í–‰
        def run_retraining():
            global retraining_status
            try:
                retraining_status['message'] = 'í”¼ë“œë°± ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ìˆìŠµë‹ˆë‹¤...'
                retraining_status['progress'] = 10
                
                retrainer = ModelRetrainer()
                
                retraining_status['message'] = 'í›ˆë ¨ ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤...'
                retraining_status['progress'] = 20
                
                feedback_data = retrainer.collect_feedback_data()
                if feedback_data is None:
                    retraining_status = {
                        'status': 'failed',
                        'progress': 0,
                        'message': 'í”¼ë“œë°± ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.'
                    }
                    return
                
                retraining_status['message'] = 'ëª¨ë¸ì„ ì¬í•™ìŠµí•˜ê³  ìˆìŠµë‹ˆë‹¤...'
                retraining_status['progress'] = 40
                
                training_data = retrainer.prepare_training_data(feedback_data)
                if training_data is None:
                    retraining_status = {
                        'status': 'failed',
                        'progress': 0,
                        'message': 'í›ˆë ¨ ë°ì´í„° ì¤€ë¹„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.'
                    }
                    return
                
                retraining_status['progress'] = 60
                
                if not retrainer.retrain_model(training_data):
                    retraining_status = {
                        'status': 'failed',
                        'progress': 0,
                        'message': 'ëª¨ë¸ ì¬í•™ìŠµì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.'
                    }
                    return
                
                retraining_status['message'] = 'ëª¨ë¸ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤...'
                retraining_status['progress'] = 80
                
                performance = retrainer.evaluate_model()
                
                retraining_status['message'] = 'ëª¨ë¸ì„ ì—…ë°ì´íŠ¸í•˜ê³  ìˆìŠµë‹ˆë‹¤...'
                retraining_status['progress'] = 90
                
                if retrainer.update_model():
                    retraining_status = {
                        'status': 'completed',
                        'progress': 100,
                        'message': 'ëª¨ë¸ ì¬í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!',
                        'performance': performance
                    }
                else:
                    retraining_status = {
                        'status': 'failed',
                        'progress': 0,
                        'message': 'ëª¨ë¸ ì—…ë°ì´íŠ¸ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.'
                    }
                    
            except Exception as e:
                retraining_status = {
                    'status': 'failed',
                    'progress': 0,
                    'message': f'ì¬í•™ìŠµ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
                }
        
        # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ì¬í•™ìŠµ ì‹¤í–‰
        thread = threading.Thread(target=run_retraining)
        thread.daemon = True
        thread.start()
        
        return jsonify({
            'success': True,
            'message': 'ì¬í•™ìŠµì„ ì‹œì‘í–ˆìŠµë‹ˆë‹¤.',
            'status': retraining_status
        })
        
    except Exception as e:
        return jsonify({'error': f'ì¬í•™ìŠµ ì‹œì‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}), 500

@app.route('/retrain/status')
def get_retraining_status():
    """ì¬í•™ìŠµ ìƒíƒœ í™•ì¸"""
    global retraining_status
    return jsonify(retraining_status)

@app.route('/feedback/stats')
def get_feedback_stats():
    """í”¼ë“œë°± í†µê³„ ì •ë³´"""
    try:
        feedback_files = list(Path('data/feedback').glob('*.json'))
        
        total_feedback = len(feedback_files)
        incorrect_feedback = 0
        recent_feedback = 0
        
        # ìµœê·¼ 7ì¼ê°„ì˜ í”¼ë“œë°±
        cutoff_date = datetime.now() - timedelta(days=7)
        
        for file_path in feedback_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    
                if data.get('user_feedback') == 'incorrect':
                    incorrect_feedback += 1
                
                feedback_date = datetime.fromisoformat(data['timestamp'])
                if feedback_date >= cutoff_date:
                    recent_feedback += 1
                    
            except:
                continue
        
        stats = {
            'total_feedback': total_feedback,
            'incorrect_feedback': incorrect_feedback,
            'recent_feedback': recent_feedback,
            'can_retrain': total_feedback >= 50 and incorrect_feedback >= 10
        }
        
        return jsonify(stats)
        
    except Exception as e:
        return jsonify({'error': f'í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}), 500

if __name__ == '__main__':
    print("ğŸš€ AI ì´ë¯¸ì§€ ë¶„ë¥˜ ì›¹ì‚¬ì´íŠ¸ ì‹œì‘ ì¤‘...")
    
    # Heroku ë°°í¬ë¥¼ ìœ„í•œ í¬íŠ¸ ì„¤ì •
    port = int(os.environ.get('PORT', 8080))
    debug_mode = os.environ.get('FLASK_ENV') != 'production'
    
    if debug_mode:
        print("ğŸ“± ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8080 ìœ¼ë¡œ ì ‘ì†í•˜ì„¸ìš”!")
        app.run(debug=True, host='127.0.0.1', port=port)
    else:
        print(f"ğŸŒ Herokuì—ì„œ í¬íŠ¸ {port}ë¡œ ì‹¤í–‰ ì¤‘...")
        app.run(debug=False, host='0.0.0.0', port=port)
