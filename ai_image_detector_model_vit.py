# -*- coding: utf-8 -*-
"""AI Image Detector Model VIT

ì•„ë‚˜ì½˜ë‹¤ íŒŒì´ì¬3 í™˜ê²½ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥í•˜ë„ë¡ ìˆ˜ì •ëœ ë²„ì „
ë¡œì»¬ ë°ì´í„° ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ì—¬ AI ìƒì„± ì´ë¯¸ì§€ì™€ ì‹¤ì œ ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•˜ëŠ” ViT ëª¨ë¸
"""

"""
=== AI Cursor / ì•„ë‚˜ì½˜ë‹¤ íŒŒì´ì¬3 í™˜ê²½ì—ì„œ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ê°€ì´ë“œ ===

ğŸš€ AI Cursorì—ì„œ ì‹¤í–‰í•˜ëŠ” ë°©ë²•:
1. Cursor í„°ë¯¸ë„ì—ì„œ ì§ì ‘ ì‹¤í–‰:
   - Ctrl+` (ë°±í‹±)ìœ¼ë¡œ í„°ë¯¸ë„ ì—´ê¸°
   - python ai_image_detector_model_vit.py

2. Cursorì˜ Python ì¸í„°í”„ë¦¬í„°ì—ì„œ ì‹¤í–‰:
   - Shift+Enterë¡œ ì…€ ë‹¨ìœ„ ì‹¤í–‰
   - ë˜ëŠ” ì „ì²´ íŒŒì¼ ì„ íƒ í›„ Ctrl+Enter

ğŸ“¦ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (Cursor í„°ë¯¸ë„ì—ì„œ):
1. PyTorch ì„¤ì¹˜ (GPU ì‚¬ìš© ì‹œ):
   conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia

2. PyTorch ì„¤ì¹˜ (CPUë§Œ ì‚¬ìš© ì‹œ):
   conda install pytorch torchvision torchaudio cpuonly -c pytorch

3. ê¸°íƒ€ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜:
   pip install transformers datasets evaluate accelerate imbalanced-learn
   pip install huggingface_hub tqdm matplotlib scikit-learn pandas numpy

âœ… ì‹¤í–‰ ì „ í™•ì¸ì‚¬í•­:
   - ë°ì´í„° ê²½ë¡œê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸: '/Users/yanggangyi/fastcampus/Hugging Face Project/Ai image detector/data1/train'
   - FAKEì™€ REAL í´ë”ì— ì´ë¯¸ì§€ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
   - ì¶©ë¶„í•œ ë””ìŠ¤í¬ ê³µê°„ì´ ìˆëŠ”ì§€ í™•ì¸ (ëª¨ë¸ ì €ì¥ìš©)
   - Python ì¸í„°í”„ë¦¬í„°ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸

ğŸ¯ ì‹¤í–‰ ë°©ë²•:
   - Cursor í„°ë¯¸ë„: python ai_image_detector_model_vit.py
   - ë˜ëŠ” Cursorì—ì„œ íŒŒì¼ì„ ì—´ê³  Shift+Enterë¡œ ì…€ ë‹¨ìœ„ ì‹¤í–‰
"""

# =============================================================================
# ì…€ 1: ë¼ì´ë¸ŒëŸ¬ë¦¬ import ë° ê¸°ë³¸ ì„¤ì •
# =============================================================================

# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import
import warnings  # ê²½ê³  ë©”ì‹œì§€ ì²˜ë¦¬
warnings.filterwarnings("ignore")  # ì‹¤í–‰ ì¤‘ ê²½ê³  ë¬´ì‹œ

import gc  # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
import numpy as np  # ìˆ˜ì¹˜ ì—°ì‚°
import pandas as pd  # ë°ì´í„° ì¡°ì‘
import itertools  # ë°˜ë³µì ë° ë£¨í•‘
from collections import Counter  # ìš”ì†Œ ì¹´ìš´íŒ…
import matplotlib.pyplot as plt  # ë°ì´í„° ì‹œê°í™”
from sklearn.metrics import (  # scikit-learn ë©”íŠ¸ë¦­
    accuracy_score,  # ì •í™•ë„ ê³„ì‚°
    roc_auc_score,  # ROC AUC ì ìˆ˜
    confusion_matrix,  # í˜¼ë™ í–‰ë ¬
    classification_report,  # ë¶„ë¥˜ ë³´ê³ ì„œ
    f1_score  # F1 ì ìˆ˜
)

# ì»¤ìŠ¤í…€ ëª¨ë“ˆ ë° í´ë˜ìŠ¤ import
from imblearn.over_sampling import RandomOverSampler  # ëœë¤ ì˜¤ë²„ìƒ˜í”Œë§
import accelerate  # ê°€ì†í™” ëª¨ë“ˆ
import evaluate  # í‰ê°€ ëª¨ë“ˆ
from datasets import Dataset, Image, ClassLabel  # ë°ì´í„°ì…‹, ì´ë¯¸ì§€, í´ë˜ìŠ¤ ë¼ë²¨
from transformers import (  # Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ëª¨ë“ˆë“¤
    TrainingArguments,  # í›ˆë ¨ ì¸ìˆ˜
    Trainer,  # ëª¨ë¸ í›ˆë ¨
    ViTImageProcessor,  # ViT ëª¨ë¸ìš© ì´ë¯¸ì§€ ì²˜ë¦¬
    ViTForImageClassification,  # ì´ë¯¸ì§€ ë¶„ë¥˜ìš© ViT ëª¨ë¸
    DefaultDataCollator  # ê¸°ë³¸ ë°ì´í„° ì½œë ˆì´í„°
)
import torch  # PyTorch ë”¥ëŸ¬ë‹
from torch.utils.data import DataLoader  # ë°ì´í„° ë¡œë” ìƒì„±
from torchvision.transforms import (  # ì´ë¯¸ì§€ ë³€í™˜ í•¨ìˆ˜ë“¤
    CenterCrop,  # ì´ë¯¸ì§€ ì¤‘ì•™ í¬ë¡­
    Compose,  # ì—¬ëŸ¬ ì´ë¯¸ì§€ ë³€í™˜ ì¡°í•©
    Normalize,  # ì´ë¯¸ì§€ í”½ì…€ ê°’ ì •ê·œí™”
    RandomRotation,  # ëœë¤ íšŒì „ ì ìš©
    RandomResizedCrop,  # ëœë¤ í¬ë¡­ ë° ë¦¬ì‚¬ì´ì¦ˆ
    RandomHorizontalFlip,  # ëœë¤ ìˆ˜í‰ ë’¤ì§‘ê¸°
    RandomAdjustSharpness,  # ëœë¤ ì„ ëª…ë„ ì¡°ì •
    Resize,  # ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ
    ToTensor  # ì´ë¯¸ì§€ë¥¼ PyTorch í…ì„œë¡œ ë³€í™˜
)

# PIL ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ í•„ìš”í•œ ëª¨ë“ˆ import
from PIL import ImageFile

# ì˜ë¦° ì´ë¯¸ì§€ ë¡œë“œ ì˜µì…˜ í™œì„±í™”
# ì´ ì„¤ì •ì€ ì†ìƒë˜ê±°ë‚˜ ë¶ˆì™„ì „í•œ ì´ë¯¸ì§€ë„ ë¡œë“œ ì‹œë„í•˜ë„ë¡ í—ˆìš©
ImageFile.LOAD_TRUNCATED_IMAGES = True

print("âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì™„ë£Œ!")

# =============================================================================
# ì…€ 2: ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬
# =============================================================================

# ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬
from pathlib import Path
from tqdm import tqdm
import os

# ë¡œì»¬ ë°ì´í„° ê²½ë¡œ ì„¤ì •
data_path = '/Users/yanggangyi/fastcampus/Hugging Face Project/Ai image detector/data1/train'

# íŒŒì¼ëª…ê³¼ ë¼ë²¨ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
file_names = []
labels = []

print(f"ë°ì´í„° ë¡œë”© ì‹œì‘: {data_path}")
print("ì§€ì›ë˜ëŠ” ì´ë¯¸ì§€ í™•ì¥ì: .jpg, .jpeg, .png, .bmp, .tiff")

# ì§€ì •ëœ ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  ì´ë¯¸ì§€ íŒŒì¼ì„ ìˆœíšŒ
image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff']
for ext in image_extensions:
    for file in tqdm(sorted(Path(data_path).glob(f'*/*{ext}')), desc=f"ë¡œë”© ì¤‘ {ext}"):
        label = str(file).split('/')[-2]  # íŒŒì¼ ê²½ë¡œì—ì„œ ë¼ë²¨ ì¶”ì¶œ
        labels.append(label)  # ë¼ë²¨ì„ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
        file_names.append(str(file))  # íŒŒì¼ ê²½ë¡œë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€

# íŒŒì¼ëª…ê³¼ ë¼ë²¨ì˜ ì´ ê°œìˆ˜ ì¶œë ¥
print(f"ì´ íŒŒì¼ ìˆ˜: {len(file_names)}")
print(f"ì´ ë¼ë²¨ ìˆ˜: {len(labels)}")
print(f"ê³ ìœ  ë¼ë²¨: {set(labels)}")
print("âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ!")

# =============================================================================
# ì…€ 3: ë°ì´í„°í”„ë ˆì„ ìƒì„± ë° ì˜¤ë²„ìƒ˜í”Œë§
# =============================================================================

# ìˆ˜ì§‘ëœ íŒŒì¼ëª…ê³¼ ë¼ë²¨ë¡œë¶€í„° pandas DataFrame ìƒì„±
df = pd.DataFrame.from_dict({"image": file_names, "label": labels})
print(f"ë°ì´í„°í”„ë ˆì„ í¬ê¸°: {df.shape}")

# ë°ì´í„°í”„ë ˆì„ì˜ ì²« 5í–‰ ì¶œë ¥
print("\në°ì´í„°í”„ë ˆì„ ìƒ˜í”Œ:")
print(df.head())

# ê³ ìœ  ë¼ë²¨ í™•ì¸
print(f"\nê³ ìœ  ë¼ë²¨: {df['label'].unique()}")

# í´ë˜ìŠ¤ë³„ ë°ì´í„° ë¶„í¬ í™•ì¸
print("\ní´ë˜ìŠ¤ë³„ ë°ì´í„° ë¶„í¬:")
print(df['label'].value_counts())

# ì†Œìˆ˜ í´ë˜ìŠ¤ ëœë¤ ì˜¤ë²„ìƒ˜í”Œë§
# 'y'ëŠ” ì˜ˆì¸¡í•˜ê³ ì í•˜ëŠ” íƒ€ê²Ÿ ë³€ìˆ˜(ë¼ë²¨)ë¥¼ í¬í•¨
y = df[['label']]

# í”¼ì²˜ì™€ íƒ€ê²Ÿ ë³€ìˆ˜ë¥¼ ë¶„ë¦¬í•˜ê¸° ìœ„í•´ DataFrame 'df'ì—ì„œ 'label' ì»¬ëŸ¼ ì œê±°
df = df.drop(['label'], axis=1)

# ì§€ì •ëœ ëœë¤ ì‹œë“œ(random_state=83)ë¡œ RandomOverSampler ê°ì²´ ìƒì„±
ros = RandomOverSampler(random_state=83)

# RandomOverSamplerë¥¼ ì‚¬ìš©í•˜ì—¬ ì†Œìˆ˜ í´ë˜ìŠ¤ë¥¼ ì˜¤ë²„ìƒ˜í”Œë§í•˜ì—¬ ë°ì´í„°ì…‹ ì¬ìƒ˜í”Œë§
# 'df'ëŠ” í”¼ì²˜ ë°ì´í„°ë¥¼ í¬í•¨í•˜ê³ , 'y_resampled'ëŠ” ì¬ìƒ˜í”Œë§ëœ íƒ€ê²Ÿ ë³€ìˆ˜ë¥¼ í¬í•¨
df, y_resampled = ros.fit_resample(df, y)

# ë” ì´ìƒ í•„ìš”í•˜ì§€ ì•Šì€ ì›ë³¸ 'y' ë³€ìˆ˜ë¥¼ ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ì‚­ì œ
del y

# ì¬ìƒ˜í”Œë§ëœ íƒ€ê²Ÿ ë³€ìˆ˜ 'y_resampled'ë¥¼ DataFrame 'df'ì˜ ìƒˆë¡œìš´ 'label' ì»¬ëŸ¼ìœ¼ë¡œ ì¶”ê°€
df['label'] = y_resampled

# ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ë” ì´ìƒ í•„ìš”í•˜ì§€ ì•Šì€ 'y_resampled' ë³€ìˆ˜ ì‚­ì œ
del y_resampled

# ì‚­ì œëœ ë³€ìˆ˜ë“¤ë¡œ ì‚¬ìš©ëœ ë©”ëª¨ë¦¬ë¥¼ í•´ì œí•˜ê¸° ìœ„í•´ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ìˆ˜í–‰
gc.collect()

print(f"\nì˜¤ë²„ìƒ˜í”Œë§ í›„ ë°ì´í„°í”„ë ˆì„ í¬ê¸°: {df.shape}")
print("ì˜¤ë²„ìƒ˜í”Œë§ í›„ í´ë˜ìŠ¤ë³„ ë¶„í¬:")
print(df['label'].value_counts())
print("âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ!")

# =============================================================================
# ì…€ 4: ë°ì´í„°ì…‹ ìƒì„± ë° ë¼ë²¨ ë§¤í•‘
# =============================================================================

# Pandas DataFrameìœ¼ë¡œë¶€í„° ë°ì´í„°ì…‹ ìƒì„±
dataset = Dataset.from_pandas(df).cast_column("image", Image())

# ë°ì´í„°ì…‹ì˜ ì²« ë²ˆì§¸ ì´ë¯¸ì§€ í‘œì‹œ
print("ë°ì´í„°ì…‹ì˜ ì²« ë²ˆì§¸ ì´ë¯¸ì§€:")
print(dataset[0]["image"])

# ê³ ìœ  ë¼ë²¨ ë¦¬ìŠ¤íŠ¸ ìƒì„±
labels_list = ['REAL', 'FAKE']

# ë¼ë²¨ê³¼ ID ê°„ì˜ ë§¤í•‘ì„ ìœ„í•œ ë¹ˆ ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”
label2id, id2label = dict(), dict()

# ê³ ìœ  ë¼ë²¨ì„ ìˆœíšŒí•˜ë©° ê° ë¼ë²¨ì— IDë¥¼ í• ë‹¹í•˜ê³ , ê·¸ ë°˜ëŒ€ë„ ìˆ˜í–‰
for i, label in enumerate(labels_list):
    label2id[label] = i  # ë¼ë²¨ì„ í•´ë‹¹ IDì— ë§¤í•‘
    id2label[i] = label  # IDë¥¼ í•´ë‹¹ ë¼ë²¨ì— ë§¤í•‘

# ì°¸ì¡°ë¥¼ ìœ„í•œ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ì¶œë ¥
print("ID to Label ë§¤í•‘:", id2label)
print("Label to ID ë§¤í•‘:", label2id)

# ë¼ë²¨ì„ IDì™€ ë§¤ì¹­í•˜ê¸° ìœ„í•œ ClassLabel ìƒì„±
ClassLabels = ClassLabel(num_classes=len(labels_list), names=labels_list)

# ë¼ë²¨ì„ IDë¡œ ë§¤í•‘í•˜ëŠ” í•¨ìˆ˜
def map_label2id(example):
    example['label'] = ClassLabels.str2int(example['label'])
    return example

# ë°ì´í„°ì…‹ì— ë¼ë²¨ ë§¤í•‘ ì ìš©
dataset = dataset.map(map_label2id, batched=True)

# ë¼ë²¨ ì»¬ëŸ¼ì„ ClassLabel ê°ì²´ë¡œ ìºìŠ¤íŒ…
dataset = dataset.cast_column('label', ClassLabels)

# 60-40 ë¶„í•  ë¹„ìœ¨ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì…‹ì„ í›ˆë ¨ ë° í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë¶„í• 
dataset = dataset.train_test_split(test_size=0.4, shuffle=True, stratify_by_column="label")

# ë¶„í• ëœ ë°ì´í„°ì…‹ì—ì„œ í›ˆë ¨ ë°ì´í„° ì¶”ì¶œ
train_data = dataset['train']

# ë¶„í• ëœ ë°ì´í„°ì…‹ì—ì„œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¶”ì¶œ
test_data = dataset['test']

print(f"í›ˆë ¨ ë°ì´í„° í¬ê¸°: {len(train_data)}")
print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°: {len(test_data)}")
print("âœ… ë°ì´í„°ì…‹ ìƒì„± ë° ë¶„í•  ì™„ë£Œ!")

# =============================================================================
# ì…€ 5: ëª¨ë¸ ë° ì „ì²˜ë¦¬ê¸° ì„¤ì •
# =============================================================================

# ì‚¬ì „ í›ˆë ¨ëœ ViT ëª¨ë¸ ë¬¸ìì—´ ì •ì˜
model_str = "dima806/ai_vs_real_image_detection"

# ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ë¡œë¶€í„° ViT ëª¨ë¸ ì…ë ¥ìš© í”„ë¡œì„¸ì„œ ìƒì„±
processor = ViTImageProcessor.from_pretrained(model_str)

# ì •ê·œí™”ì— ì‚¬ìš©ë˜ëŠ” ì´ë¯¸ì§€ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ê²€ìƒ‰
image_mean, image_std = processor.image_mean, processor.image_std

# ViT ëª¨ë¸ì˜ ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°(ë†’ì´) ê°€ì ¸ì˜¤ê¸°
size = processor.size["height"]
print(f"ì´ë¯¸ì§€ í¬ê¸°: {size}")

# ì…ë ¥ ì´ë¯¸ì§€ì— ëŒ€í•œ ì •ê·œí™” ë³€í™˜ ì •ì˜
normalize = Normalize(mean=image_mean, std=image_std)

# í›ˆë ¨ ë°ì´í„°ì— ëŒ€í•œ ë³€í™˜ ì„¸íŠ¸ ì •ì˜
_train_transforms = Compose(
    [
        Resize((size, size)),             # ì´ë¯¸ì§€ë¥¼ ViT ëª¨ë¸ì˜ ì…ë ¥ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        RandomRotation(90),               # ëœë¤ íšŒì „ ì ìš©
        RandomAdjustSharpness(2),         # ëœë¤ ì„ ëª…ë„ ì¡°ì •
        ToTensor(),                       # ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜
        normalize                         # í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ì •ê·œí™”
    ]
)

# ê²€ì¦ ë°ì´í„°ì— ëŒ€í•œ ë³€í™˜ ì„¸íŠ¸ ì •ì˜
_val_transforms = Compose(
    [
        Resize((size, size)),             # ì´ë¯¸ì§€ë¥¼ ViT ëª¨ë¸ì˜ ì…ë ¥ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        ToTensor(),                       # ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜
        normalize                         # í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ì •ê·œí™”
    ]
)

# ì˜ˆì œ ë°°ì¹˜ì— í›ˆë ¨ ë³€í™˜ì„ ì ìš©í•˜ëŠ” í•¨ìˆ˜ ì •ì˜
def train_transforms(examples):
    examples['pixel_values'] = [_train_transforms(image.convert("RGB")) for image in examples['image']]
    return examples

# ì˜ˆì œ ë°°ì¹˜ì— ê²€ì¦ ë³€í™˜ì„ ì ìš©í•˜ëŠ” í•¨ìˆ˜ ì •ì˜
def val_transforms(examples):
    examples['pixel_values'] = [_val_transforms(image.convert("RGB")) for image in examples['image']]
    return examples

# í›ˆë ¨ ë°ì´í„°ì— ë³€í™˜ ì„¤ì •
train_data.set_transform(train_transforms)

# í…ŒìŠ¤íŠ¸/ê²€ì¦ ë°ì´í„°ì— ë³€í™˜ ì„¤ì •
test_data.set_transform(val_transforms)

# ëª¨ë¸ í›ˆë ¨ì„ ìœ„í•´ ë°°ì¹˜ ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ëŠ” ì½œë ˆì´íŠ¸ í•¨ìˆ˜ ì •ì˜
def collate_fn(examples):
    # ê°œë³„ ì˜ˆì œì˜ í”½ì…€ ê°’ì„ ë‹¨ì¼ í…ì„œë¡œ ìŠ¤íƒ
    pixel_values = torch.stack([example["pixel_values"] for example in examples])

    # ì˜ˆì œì˜ ë¼ë²¨ ë¬¸ìì—´ì„ label2id ë”•ì…”ë„ˆë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ í•´ë‹¹ ìˆ«ì IDë¡œ ë³€í™˜
    labels = torch.tensor([example['label'] for example in examples])

    # ë°°ì¹˜ëœ í”½ì…€ ê°’ê³¼ ë¼ë²¨ì„ í¬í•¨í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ ë°˜í™˜
    return {"pixel_values": pixel_values, "labels": labels}

print("âœ… ëª¨ë¸ ë° ì „ì²˜ë¦¬ê¸° ì„¤ì • ì™„ë£Œ!")

# =============================================================================
# ì…€ 6: ëª¨ë¸ ë¡œë“œ ë° í›ˆë ¨ ì„¤ì •
# =============================================================================

# ì§€ì •ëœ ì¶œë ¥ ë¼ë²¨ ìˆ˜ë¡œ ì‚¬ì „ í›ˆë ¨ëœ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ViTForImageClassification ëª¨ë¸ ìƒì„±
model = ViTForImageClassification.from_pretrained(model_str, num_labels=len(labels_list))

# ë‚˜ì¤‘ì— ì°¸ì¡°í•  ìˆ˜ ìˆë„ë¡ í´ë˜ìŠ¤ ë¼ë²¨ì„ í•´ë‹¹ ì¸ë±ìŠ¤ì— ë§¤í•‘í•˜ëŠ” ì„¤ì • êµ¬ì„±
model.config.id2label = id2label
model.config.label2id = label2id

# ëª¨ë¸ì˜ í›ˆë ¨ ê°€ëŠ¥í•œ ë§¤ê°œë³€ìˆ˜ ìˆ˜ë¥¼ ë°±ë§Œ ë‹¨ìœ„ë¡œ ê³„ì‚°í•˜ê³  ì¶œë ¥
print(f"í›ˆë ¨ ê°€ëŠ¥í•œ ë§¤ê°œë³€ìˆ˜ ìˆ˜: {model.num_parameters(only_trainable=True) / 1e6:.2f}M")

# 'evaluate' ëª¨ë“ˆì—ì„œ ì •í™•ë„ ë©”íŠ¸ë¦­ ë¡œë“œ
accuracy = evaluate.load("accuracy")

# í‰ê°€ ë©”íŠ¸ë¦­ì„ ê³„ì‚°í•˜ëŠ” 'compute_metrics' í•¨ìˆ˜ ì •ì˜
def compute_metrics(eval_pred):
    # í‰ê°€ ì˜ˆì¸¡ ê°ì²´ì—ì„œ ëª¨ë¸ ì˜ˆì¸¡ ì¶”ì¶œ
    predictions = eval_pred.predictions

    # í‰ê°€ ì˜ˆì¸¡ ê°ì²´ì—ì„œ ì‹¤ì œ ë¼ë²¨ ì¶”ì¶œ
    label_ids = eval_pred.label_ids

    # ë¡œë“œëœ ì •í™•ë„ ë©”íŠ¸ë¦­ì„ ì‚¬ìš©í•˜ì—¬ ì •í™•ë„ ê³„ì‚°
    # ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ í´ë˜ìŠ¤ë¥¼ ì„ íƒí•˜ì—¬ ëª¨ë¸ ì˜ˆì¸¡ì„ í´ë˜ìŠ¤ ë¼ë²¨ë¡œ ë³€í™˜ (argmax)
    predicted_labels = predictions.argmax(axis=1)

    # ì˜ˆì¸¡ëœ ë¼ë²¨ì„ ì‹¤ì œ ë¼ë²¨ê³¼ ë¹„êµí•˜ì—¬ ì •í™•ë„ ì ìˆ˜ ê³„ì‚°
    acc_score = accuracy.compute(predictions=predicted_labels, references=label_ids)['accuracy']

    # "accuracy" í‚¤ë¥¼ ê°€ì§„ ë”•ì…”ë„ˆë¦¬ë¡œ ê³„ì‚°ëœ ì •í™•ë„ ë°˜í™˜
    return {
        "accuracy": acc_score
    }

# í›ˆë ¨ ë° í‰ê°€ ì¤‘ì— ì‚¬ìš©ë  í‰ê°€ ë©”íŠ¸ë¦­ì˜ ì´ë¦„ ì •ì˜
metric_name = "accuracy"

# ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ì™€ ì¶œë ¥ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬ë¥¼ ìƒì„±í•˜ëŠ” ë° ì‚¬ìš©ë  ëª¨ë¸ ì´ë¦„ ì •ì˜
model_name = "ai_vs_real_image_detection"
model_save_path = f"./{model_name}"  # ë¡œì»¬ ì €ì¥ ê²½ë¡œ

# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ ë° ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ì‚¬ìš© ì¤‘ì¸ ë””ë°”ì´ìŠ¤: {device}")

# GPU ë©”ëª¨ë¦¬ ì •ë³´ ì¶œë ¥ (GPU ì‚¬ìš© ì‹œ)
if torch.cuda.is_available():
    print(f"GPU ì´ë¦„: {torch.cuda.get_device_name(0)}")
    print(f"GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")

# ëª¨ë¸ í›ˆë ¨ì„ ìœ„í•œ ì—í¬í¬ ìˆ˜ ì •ì˜
num_train_epochs = 2

# GPU/CPUì— ë”°ë¥¸ ë°°ì¹˜ í¬ê¸° ì¡°ì •
if torch.cuda.is_available():
    train_batch_size = 32  # GPU ì‚¬ìš© ì‹œ
    eval_batch_size = 16
    print("GPU ì‚¬ìš© - ë°°ì¹˜ í¬ê¸°: 32 (í›ˆë ¨), 16 (í‰ê°€)")
else:
    train_batch_size = 8   # CPU ì‚¬ìš© ì‹œ
    eval_batch_size = 4
    print("CPU ì‚¬ìš© - ë°°ì¹˜ í¬ê¸°: 8 (í›ˆë ¨), 4 (í‰ê°€)")

# í›ˆë ¨ ì„¤ì •ì„ êµ¬ì„±í•˜ê¸° ìœ„í•œ TrainingArguments ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
args = TrainingArguments(
    # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ì™€ ì¶œë ¥ì´ ì €ì¥ë  ë””ë ‰í† ë¦¬ ì§€ì •
    output_dir=model_name,

    # í›ˆë ¨ ë¡œê·¸ê°€ ì €ì¥ë  ë””ë ‰í† ë¦¬ ì§€ì •
    logging_dir='./logs',

    # ê° ì—í¬í¬ ëì—ì„œ ìˆ˜í–‰ë˜ëŠ” í‰ê°€ ì „ëµ ì •ì˜
    eval_strategy="epoch",

    # ì˜µí‹°ë§ˆì´ì €ë¥¼ ìœ„í•œ í•™ìŠµë¥  ì„¤ì •
    learning_rate=1e-6,

    # ê° ë””ë°”ì´ìŠ¤ì—ì„œ í›ˆë ¨ì„ ìœ„í•œ ë°°ì¹˜ í¬ê¸° ì •ì˜
    per_device_train_batch_size=train_batch_size,

    # ê° ë””ë°”ì´ìŠ¤ì—ì„œ í‰ê°€ë¥¼ ìœ„í•œ ë°°ì¹˜ í¬ê¸° ì •ì˜
    per_device_eval_batch_size=eval_batch_size,

    # ì´ í›ˆë ¨ ì—í¬í¬ ìˆ˜ ì§€ì •
    num_train_epochs=num_train_epochs,

    # ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•œ ê°€ì¤‘ì¹˜ ê°ì‡  ì ìš©
    weight_decay=0.02,

    # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ìœ„í•œ ì›Œë°ì—… ìŠ¤í… ìˆ˜ ì„¤ì •
    warmup_steps=50,

    # ë°ì´í„°ì…‹ì—ì„œ ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼ ì œê±° ë¹„í™œì„±í™”
    remove_unused_columns=False,

    # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì „ëµ ì •ì˜ (ì´ ê²½ìš° ì—í¬í¬ë‹¹)
    save_strategy='epoch',

    # í›ˆë ¨ ëì— ìµœê³  ëª¨ë¸ ë¡œë“œ
    load_best_model_at_end=True,

    # ê³µê°„ ì ˆì•½ì„ ìœ„í•´ ì €ì¥ë˜ëŠ” ì´ ì²´í¬í¬ì¸íŠ¸ ìˆ˜ ì œí•œ
    save_total_limit=1,

    # í›ˆë ¨ ì§„í–‰ ìƒí™©ì„ ë³´ê³ í•˜ì§€ ì•Šë„ë¡ ì§€ì •
    report_to="none"  # ë¡œê·¸ ì—†ìŒ
)

print("âœ… ëª¨ë¸ ë¡œë“œ ë° í›ˆë ¨ ì„¤ì • ì™„ë£Œ!")

# =============================================================================
# ì…€ 7: í›ˆë ¨ ë° í‰ê°€
# =============================================================================

# ì–¸ì–´ ëª¨ë¸ íŒŒì¸íŠœë‹ì„ ìœ„í•œ Trainer ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
# - `model`: íŒŒì¸íŠœë‹í•  ì‚¬ì „ í›ˆë ¨ëœ ì–¸ì–´ ëª¨ë¸
# - `args`: í›ˆë ¨ì„ ìœ„í•œ êµ¬ì„± ì„¤ì • ë° í•˜ì´í¼íŒŒë¼ë¯¸í„°
# - `train_dataset`: ëª¨ë¸ í›ˆë ¨ì— ì‚¬ìš©ë˜ëŠ” ë°ì´í„°ì…‹
# - `eval_dataset`: í›ˆë ¨ ì¤‘ ëª¨ë¸ í‰ê°€ì— ì‚¬ìš©ë˜ëŠ” ë°ì´í„°ì…‹
# - `data_collator`: ë°ì´í„° ë°°ì¹˜ê°€ ì–´ë–»ê²Œ ì½œë ˆì´íŠ¸ë˜ê³  ì²˜ë¦¬ë˜ëŠ”ì§€ ì •ì˜í•˜ëŠ” í•¨ìˆ˜
# - `compute_metrics`: ì‚¬ìš©ì ì •ì˜ í‰ê°€ ë©”íŠ¸ë¦­ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜
# - `tokenizer`: í…ìŠ¤íŠ¸ ë°ì´í„° ì²˜ë¦¬ì— ì‚¬ìš©ë˜ëŠ” í† í¬ë‚˜ì´ì €

trainer = Trainer(
    model,
    args,
    train_dataset=train_data,
    eval_dataset=test_data,
    data_collator=collate_fn,
    compute_metrics=compute_metrics,
    tokenizer=processor,
)

print("ğŸš€ í›ˆë ¨ ì‹œì‘ ì „ ì‚¬ì „ í›ˆë ¨ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€...")
# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì—ì„œ ì‚¬ì „ í›ˆë ¨ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€
# ì´ í•¨ìˆ˜ëŠ” ì •í™•ë„, ì†ì‹¤ ë“± ë‹¤ì–‘í•œ ë©”íŠ¸ë¦­ì„ ê³„ì‚°í•˜ì—¬
# ëª¨ë¸ì´ ë³´ì§€ ëª»í•œ ë°ì´í„°ì—ì„œ ì–¼ë§ˆë‚˜ ì˜ ìˆ˜í–‰í•˜ëŠ”ì§€ í‰ê°€
pre_training_results = trainer.evaluate()
print(f"ì‚¬ì „ í›ˆë ¨ ëª¨ë¸ ì •í™•ë„: {pre_training_results['eval_accuracy']:.4f}")

print("\nğŸ¯ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
# trainer ê°ì²´ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ í›ˆë ¨ ì‹œì‘
trainer.train()

print("\nğŸ“Š í›ˆë ¨ í›„ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€...")
# ê²€ì¦ ë˜ëŠ” í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì—ì„œ í›ˆë ¨ í›„ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€
# ì´ í•¨ìˆ˜ëŠ” ì •í™•ë„, ì†ì‹¤ ë“± ë‹¤ì–‘í•œ í‰ê°€ ë©”íŠ¸ë¦­ì„ ê³„ì‚°í•˜ê³ 
# ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ì˜ ìˆ˜í–‰í•˜ëŠ”ì§€ì— ëŒ€í•œ í†µì°°ì„ ì œê³µ
post_training_results = trainer.evaluate()
print(f"í›ˆë ¨ í›„ ëª¨ë¸ ì •í™•ë„: {post_training_results['eval_accuracy']:.4f}")

print("âœ… í›ˆë ¨ ë° í‰ê°€ ì™„ë£Œ!")

# =============================================================================
# ì…€ 8: ì˜ˆì¸¡ ë° ê²°ê³¼ ë¶„ì„
# =============================================================================

print("ğŸ” í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ ìˆ˜í–‰...")
# í›ˆë ¨ëœ 'trainer'ë¥¼ ì‚¬ìš©í•˜ì—¬ 'test_data'ì— ëŒ€í•œ ì˜ˆì¸¡ ìˆ˜í–‰
outputs = trainer.predict(test_data)

# ì˜ˆì¸¡ ì¶œë ¥ì—ì„œ ì–»ì€ ë©”íŠ¸ë¦­ ì¶œë ¥
print("ì˜ˆì¸¡ ê²°ê³¼ ë©”íŠ¸ë¦­:")
print(outputs.metrics)

# ëª¨ë¸ ì¶œë ¥ì—ì„œ ì‹¤ì œ ë¼ë²¨ ì¶”ì¶œ
y_true = outputs.label_ids

# ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ í´ë˜ìŠ¤ë¥¼ ì„ íƒí•˜ì—¬ ë¼ë²¨ ì˜ˆì¸¡
y_pred = outputs.predictions.argmax(1)

# í˜¼ë™ í–‰ë ¬ì„ ê·¸ë¦¬ëŠ” í•¨ìˆ˜ ì •ì˜
def plot_confusion_matrix(cm, classes, title='Confusion Matrix', cmap=plt.cm.Blues, figsize=(10, 8)):
    """
    ì´ í•¨ìˆ˜ëŠ” í˜¼ë™ í–‰ë ¬ì„ ê·¸ë¦½ë‹ˆë‹¤.

    ë§¤ê°œë³€ìˆ˜:
        cm (array-like): sklearn.metrics.confusion_matrixì—ì„œ ë°˜í™˜ëœ í˜¼ë™ í–‰ë ¬
        classes (list): í´ë˜ìŠ¤ ì´ë¦„ ëª©ë¡, ì˜ˆ: ['Class 0', 'Class 1']
        title (str): í”Œë¡¯ì˜ ì œëª©
        cmap (matplotlib colormap): í”Œë¡¯ì˜ ì»¬ëŸ¬ë§µ
    """
    # ì§€ì •ëœ í¬ê¸°ë¡œ ê·¸ë¦¼ ìƒì„±
    plt.figure(figsize=figsize)

    # ì»¬ëŸ¬ë§µì„ ì‚¬ìš©í•˜ì—¬ í˜¼ë™ í–‰ë ¬ì„ ì´ë¯¸ì§€ë¡œ í‘œì‹œ
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()

    # ì¶•ì˜ í´ë˜ìŠ¤ì— ëŒ€í•œ í‹± ë§ˆí¬ì™€ ë¼ë²¨ ì •ì˜
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=90)
    plt.yticks(tick_marks, classes)

    fmt = '.0f'
    # ì…€ì˜ ê°’ì„ ë‚˜íƒ€ë‚´ëŠ” í…ìŠ¤íŠ¸ ì£¼ì„ì„ í”Œë¡¯ì— ì¶”ê°€
    thresh = cm.max() / 2.0
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment="center", color="white" if cm[i, j] > thresh else "black")

    # ì¶•ì— ë¼ë²¨ ì§€ì •
    plt.ylabel('ì‹¤ì œ ë¼ë²¨')
    plt.xlabel('ì˜ˆì¸¡ ë¼ë²¨')

    # í”Œë¡¯ ë ˆì´ì•„ì›ƒì„ íƒ€ì´íŠ¸í•˜ê²Œ ì„¤ì •
    plt.tight_layout()
    # í”Œë¡¯ í‘œì‹œ
    plt.show()

# ì •í™•ë„ì™€ F1 ì ìˆ˜ ê³„ì‚°
accuracy = accuracy_score(y_true, y_pred)
f1 = f1_score(y_true, y_pred, average='macro')

# ì •í™•ë„ì™€ F1 ì ìˆ˜ í‘œì‹œ
print(f"\nğŸ“Š ìµœì¢… ì„±ëŠ¥ ì§€í‘œ:")
print(f"ì •í™•ë„: {accuracy:.4f}")
print(f"F1 ì ìˆ˜: {f1:.4f}")

# ë¼ë²¨ ìˆ˜ê°€ ì ì€ ê²½ìš° í˜¼ë™ í–‰ë ¬ ê°€ì ¸ì˜¤ê¸°
if len(labels_list) <= 150:
    print("\nğŸ“ˆ í˜¼ë™ í–‰ë ¬ ìƒì„± ì¤‘...")
    # í˜¼ë™ í–‰ë ¬ ê³„ì‚°
    cm = confusion_matrix(y_true, y_pred)

    # ì •ì˜ëœ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í˜¼ë™ í–‰ë ¬ í”Œë¡¯
    plot_confusion_matrix(cm, labels_list, figsize=(8, 6))

# ë§ˆì§€ë§‰ìœ¼ë¡œ ë¶„ë¥˜ ë³´ê³ ì„œ í‘œì‹œ
print("\nğŸ“‹ ë¶„ë¥˜ ë³´ê³ ì„œ:")
print(classification_report(y_true, y_pred, target_names=labels_list, digits=4))

print("âœ… ì˜ˆì¸¡ ë° ê²°ê³¼ ë¶„ì„ ì™„ë£Œ!")

# =============================================================================
# ì…€ 9: ëª¨ë¸ ì €ì¥ ë° í…ŒìŠ¤íŠ¸
# =============================================================================

print("ğŸ’¾ í›ˆë ¨ëœ ëª¨ë¸ ì €ì¥ ì¤‘...")
# í›ˆë ¨ëœ ëª¨ë¸ ì €ì¥: ì´ ì½”ë“œ ë¼ì¸ì€ trainer ê°ì²´ë¥¼ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨ëœ ëª¨ë¸ì„ ì €ì¥í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
# ëª¨ë¸ê³¼ ê´€ë ¨ ê°€ì¤‘ì¹˜ë¥¼ ì§ë ¬í™”í•˜ì—¬ ë‚˜ì¤‘ì— ì¬ë¡œë“œí•˜ê³  ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.
# ì¬í›ˆë ¨ ì—†ì´ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤.
trainer.save_model()

# 'transformers' ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ 'pipeline' í•¨ìˆ˜ import
from transformers import pipeline

# ì´ë¯¸ì§€ ë¶„ë¥˜ ì‘ì—…ì„ ìœ„í•œ íŒŒì´í”„ë¼ì¸ ìƒì„±
# ì¶”ë¡ ì— ì‚¬ìš©í•  'model_name'ê³¼ 'device'ë¥¼ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.
# - 'model_name': ì´ë¯¸ì§€ ë¶„ë¥˜ì— ì‚¬ìš©í•  ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì˜ ì´ë¦„
# - 'device': ëª¨ë¸ì„ ì‹¤í–‰í•  ë””ë°”ì´ìŠ¤ ì§€ì • (0ì€ GPU, -1ì€ CPU)
# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ì— ë”°ë¼ ìë™ìœ¼ë¡œ ì„¤ì •
device = 0 if torch.cuda.is_available() else -1
pipe = pipeline('image-classification', model=model_name, device=device)

print("ğŸ§ª ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì¤‘...")
# 'test_data' ë°ì´í„°ì…‹ì—ì„œ ì¸ë±ìŠ¤ 1ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì— ì ‘ê·¼
image = test_data[1]["image"]

# 'image' ë³€ìˆ˜ í‘œì‹œ
print("í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€:")
print(image)

# 'image' ë³€ìˆ˜ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ 'pipe' í•¨ìˆ˜ ì ìš©
print("\nì˜ˆì¸¡ ê²°ê³¼:")
result = pipe(image)
print(result)

# ì´ ì½”ë“œ ë¼ì¸ì€ test_data ë¦¬ìŠ¤íŠ¸ì˜ íŠ¹ì • ìš”ì†Œì—ì„œ "label" ì†ì„±ì— ì ‘ê·¼í•©ë‹ˆë‹¤.
# í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ì¸íŠ¸ì™€ ê´€ë ¨ëœ ì‹¤ì œ ë¼ë²¨ì„ ê²€ìƒ‰í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.
print(f"\nì‹¤ì œ ë¼ë²¨: {id2label[test_data[1]['label']]}")

print("âœ… ëª¨ë¸ ì €ì¥ ë° í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

# =============================================================================
# ì…€ 10: ëª¨ë¸ ì‚¬ìš©ë²• ì•ˆë‚´
# =============================================================================

"""# ëª¨ë¸ ì €ì¥ ë° ë¡œì»¬ ì‚¬ìš©"""

# ëª¨ë¸ì´ ë¡œì»¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.
# ì €ì¥ëœ ëª¨ë¸ì€ './ai_vs_real_image_detection' ë””ë ‰í† ë¦¬ì— ìˆìŠµë‹ˆë‹¤.
print(f"ëª¨ë¸ì´ '{model_save_path}' ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ë¡œì»¬ì—ì„œ ì €ì¥ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•:
print("\n=== ì €ì¥ëœ ëª¨ë¸ ì‚¬ìš© ë°©ë²• ===")
print("1. ìƒˆë¡œìš´ Python ìŠ¤í¬ë¦½íŠ¸ì—ì„œ:")
print("   from transformers import pipeline")
print(f"   pipe = pipeline('image-classification', model='{model_save_path}', device={device})")
print("   result = pipe('ì´ë¯¸ì§€_ê²½ë¡œ')")
print("\n2. ë˜ëŠ” ì§ì ‘ ëª¨ë¸ ë¡œë“œ:")
print("   from transformers import ViTForImageClassification, ViTImageProcessor")
print(f"   model = ViTForImageClassification.from_pretrained('{model_save_path}')")
print(f"   processor = ViTImageProcessor.from_pretrained('{model_save_path}')")

print("\n" + "="*60)
print("ğŸ‰ AI ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
print("="*60)
print(f"âœ… í›ˆë ¨ëœ ëª¨ë¸ì´ '{model_save_path}' ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
print("âœ… ì´ì œ ìƒˆë¡œìš´ ì´ë¯¸ì§€ì— ëŒ€í•´ AI ìƒì„± ì—¬ë¶€ë¥¼ ë¶„ë¥˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
print("="*60)
